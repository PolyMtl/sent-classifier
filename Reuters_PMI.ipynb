{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class McDonald_Word_List:\n",
    "    def __init__(self, pos_words, neg_words):\n",
    "        self.pos_words = pos_words\n",
    "        self.neg_words = neg_words\n",
    "        self.pos_word_counts = {word:0 for word, val in pos_words.items()}\n",
    "        self.intersection_pos = {word:0 for word, val in pos_words.items()}\n",
    "        self.neg_word_counts = {word:0 for word, val in neg_words.items()}\n",
    "        self.intersection_neg = {word:0 for word,val in neg_words.items()}\n",
    "        \n",
    "    def __str__(self):\n",
    "        print(\"\"\"Pos words: {0}\n",
    "                 Neg words: {1}\"\"\".format(\n",
    "                  len(self.pos_words),\n",
    "                  len(self.neg_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now read Bill McDonald's Excel file containing the master dictionary of financial sentiment words.\n",
    "For this task, I am using the xlrd library. For now, I am only reading the cell values that have words with positive or negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADVANCES': 2009, 'INNOVATIONS': 2009, 'ADVANTAGEOUSLY': 2009, 'ATTAINS': 2009, 'REWARDED': 2009, 'ENHANCED': 2009, 'ACHIEVING': 2009, 'ENJOYMENT': 2009, 'ENHANCES': 2009, 'EFFICIENCY': 2009, 'BETTER': 2009, 'UPTURN': 2009, 'HIGHEST': 2009, 'CONCLUSIVE': 2009, 'CHARITABLE': 2009, 'FAVORITE': 2009, 'PROGRESSING': 2009, 'EFFICIENCIES': 2009, 'UNPARALLELED': 2009, 'INNOVATED': 2009, 'TREMENDOUS': 2009, 'EXCELLENCE': 2009, 'COURTEOUS': 2009, 'EASY': 2009, 'PLENTIFUL': 2009, 'VIBRANT': 2009, 'COMPLIMENTED': 2009, 'COLLABORATE': 2009, 'LEADERSHIP': 2009, 'DESIRABLE': 2009, 'FAVORING': 2009, 'REWARDS': 2009, 'ENCOURAGEMENT': 2009, 'PRESTIGE': 2009, 'ACCLAIMED': 2009, 'SURPASSING': 2009, 'INSIGHTFUL': 2009, 'FRIENDLY': 2009, 'INGENUITY': 2009, 'POPULAR': 2009, 'HAPPINESS': 2009, 'BENEFITTING': 2009, 'OPPORTUNITIES': 2009, 'BENEFICIALLY': 2009, 'INNOVATING': 2009, 'INNOVATORS': 2009, 'ALLIANCES': 2009, 'IMPRESSED': 2009, 'IMPROVES': 2009, 'FAVORABLY': 2009, 'EXCELLENT': 2009, 'HONOR': 2009, 'DELIGHTED': 2009, 'INVENTIVE': 2009, 'WIN': 2009, 'SURPASS': 2009, 'BEAUTIFUL': 2009, 'PROGRESS': 2009, 'COLLABORATION': 2009, 'INCREDIBLE': 2009, 'UNMATCHED': 2009, 'WINNERS': 2009, 'PROSPERITY': 2009, 'GREAT': 2009, 'ABUNDANCE': 2009, 'REWARD': 2009, 'IMPRESSIVE': 2009, 'CREATIVELY': 2009, 'ENTHUSIASTIC': 2009, 'PERFECTLY': 2009, 'OUTPERFORMED': 2009, 'OPPORTUNITY': 2009, 'DESPITE': 2009, 'REBOUNDING': 2009, 'PREMIER': 2009, 'DELIGHTING': 2009, 'ENJOY': 2009, 'EASILY': 2009, 'HAPPILY': 2009, 'STRENGTHEN': 2009, 'EXCELS': 2009, 'STABILIZATION': 2009, 'EMPOWERED': 2009, 'SATISFYING': 2009, 'INVENTION': 2009, 'STRENGTHENING': 2009, 'ACHIEVED': 2009, 'LEADING': 2009, 'PROACTIVE': 2009, 'WINNING': 2009, 'PROFITABLE': 2009, 'EMPOWERS': 2009, 'PROFITABLY': 2009, 'DISTINCTIVELY': 2009, 'ABUNDANT': 2009, 'STRENGTH': 2009, 'FAVORITES': 2009, 'HAPPIEST': 2009, 'INVENTIVENESS': 2009, 'EXCLUSIVE': 2009, 'ENJOYS': 2009, 'DESTINED': 2009, 'ATTAINMENT': 2009, 'ENHANCE': 2009, 'BENEFIT': 2009, 'ADVANTAGE': 2009, 'GAINED': 2009, 'EMPOWER': 2009, 'ENJOYING': 2009, 'INFORMATIVE': 2009, 'PLEASANT': 2009, 'PROFICIENT': 2009, 'ENABLES': 2009, 'PROSPERED': 2009, 'STABILIZING': 2009, 'PROSPERING': 2009, 'PROSPEROUS': 2009, 'INVENT': 2009, 'BOLSTERING': 2009, 'PROFICIENTLY': 2009, 'COLLABORATORS': 2009, 'ADVANTAGEOUS': 2009, 'EXCLUSIVELY': 2009, 'ASSURES': 2009, 'STRENGTHENS': 2009, 'SUCCEEDED': 2009, 'EXCLUSIVITY': 2009, 'SPECTACULAR': 2009, 'IMPRESSIVELY': 2009, 'IMPROVING': 2009, 'GREATLY': 2009, 'EXCEPTIONALLY': 2009, 'FAVORABLE': 2009, 'BREAKTHROUGHS': 2009, 'ENJOYABLE': 2009, 'STABILIZES': 2009, 'STRENGTHENED': 2009, 'REVOLUTIONIZING': 2009, 'DILIGENT': 2009, 'PLEASED': 2009, 'BOOMING': 2009, 'IMPROVEMENT': 2009, 'ASSURE': 2009, 'GAINS': 2009, 'INVENTING': 2009, 'PROFITABILITY': 2009, 'WORTHY': 2009, 'PLEASURE': 2009, 'HONORABLE': 2009, 'SATISFACTION': 2009, 'EXCLUSIVENESS': 2009, 'SUCCEEDS': 2009, 'POSITIVE': 2009, 'ENCOURAGED': 2009, 'ACHIEVEMENTS': 2009, 'SATISFIED': 2009, 'SMOOTHING': 2009, 'ACCOMPLISHING': 2009, 'DELIGHT': 2009, 'COLLABORATOR': 2009, 'WINNER': 2009, 'DELIGHTFULLY': 2009, 'ACHIEVE': 2009, 'EXCELLING': 2009, 'SUCCESSFULLY': 2009, 'ADVANCEMENT': 2009, 'IMPRESS': 2009, 'SURPASSES': 2009, 'CONCLUSIVELY': 2009, 'STRENGTHS': 2009, 'CONFIDENT': 2009, 'LUCRATIVE': 2009, 'SUCCESSES': 2009, 'BOOST': 2009, 'INNOVATOR': 2009, 'BENEFITED': 2009, 'INCREDIBLY': 2009, 'COLLABORATING': 2009, 'ACCOMPLISH': 2009, 'BEST': 2012, 'IMPROVE': 2009, 'PROGRESSED': 2009, 'EXEMPLARY': 2009, 'STRONGER': 2009, 'IMPROVED': 2009, 'EFFICIENT': 2009, 'REWARDING': 2009, 'PROACTIVELY': 2009, 'ENHANCEMENT': 2009, 'CREATIVITY': 2009, 'REBOUNDED': 2009, 'ENTHUSIASM': 2009, 'DISTINCTIVENESS': 2009, 'EXCITED': 2009, 'PRESTIGIOUS': 2009, 'CONDUCIVE': 2009, 'IMPRESSING': 2009, 'DESIRED': 2009, 'PROFICIENCY': 2009, 'OUTPERFORMING': 2009, 'STABILIZATIONS': 2009, 'FANTASTIC': 2009, 'ENABLE': 2009, 'INNOVATES': 2009, 'INVENTOR': 2009, 'BRILLIANT': 2009, 'TREMENDOUSLY': 2009, 'ADVANTAGED': 2009, 'PREEMINENCE': 2009, 'SMOOTH': 2009, 'DEPENDABLE': 2009, 'COLLABORATES': 2009, 'CREATIVENESS': 2009, 'ADVANCEMENTS': 2009, 'ATTRACTIVENESS': 2009, 'VERSATILE': 2009, 'SOLVES': 2009, 'SPECTACULARLY': 2009, 'EXCEPTIONAL': 2009, 'COLLABORATIONS': 2009, 'DELIGHTFUL': 2009, 'OPTIMISTIC': 2009, 'IMPROVEMENTS': 2009, 'SATISFY': 2009, 'GREATER': 2009, 'STABILITY': 2009, 'ACHIEVEMENT': 2009, 'SATISFACTORY': 2009, 'EFFICIENTLY': 2009, 'ALLIANCE': 2009, 'HAPPY': 2009, 'BEAUTIFULLY': 2009, 'ATTRACTIVE': 2009, 'COMPLIMENTING': 2009, 'SATISFACTORILY': 2009, 'VIBRANCY': 2009, 'BENEFITTED': 2009, 'ENABLING': 2009, 'RESOLVE': 2009, 'BENEFICIAL': 2009, 'EXCITING': 2009, 'UPTURNS': 2009, 'MERITORIOUS': 2009, 'STRONGEST': 2009, 'CREATIVE': 2009, 'COMPLIMENTARY': 2009, 'CONSTRUCTIVELY': 2009, 'IMPRESSES': 2009, 'RECEPTIVE': 2009, 'COMPLIMENTS': 2009, 'POSITIVELY': 2009, 'REVOLUTIONIZED': 2009, 'ENHANCEMENTS': 2009, 'PROSPERS': 2009, 'STABILIZE': 2009, 'POPULARITY': 2009, 'INSPIRATIONAL': 2009, 'ATTAINMENTS': 2009, 'REVOLUTIONIZE': 2009, 'GAINING': 2009, 'INSPIRATION': 2009, 'BOLSTERS': 2009, 'OUTPERFORMS': 2009, 'SATISFIES': 2009, 'INNOVATION': 2009, 'EXCLUSIVES': 2009, 'ATTAINED': 2009, 'SMOOTHS': 2009, 'STABLE': 2009, 'INVENTIONS': 2009, 'DILIGENTLY': 2009, 'ACCOMPLISHMENT': 2009, 'INTEGRITY': 2009, 'INFLUENTIAL': 2009, 'EXCITEMENT': 2009, 'SUPERIOR': 2009, 'INNOVATIVENESS': 2011, 'GOOD': 2009, 'UNSURPASSED': 2009, 'CONSTRUCTIVE': 2009, 'BOOSTED': 2009, 'ACHIEVES': 2009, 'BREAKTHROUGH': 2009, 'SUCCESSFUL': 2009, 'ENCOURAGES': 2009, 'ABLE': 2009, 'ADVANTAGES': 2009, 'HONORS': 2009, 'ACCOMPLISHMENTS': 2009, 'ADVANCING': 2009, 'BENEFITING': 2009, 'INVENTORS': 2009, 'EASIER': 2009, 'EFFECTIVE': 2009, 'HONORED': 2009, 'PLEASANTLY': 2009, 'REGAINING': 2009, 'GREATEST': 2009, 'PREEMINENT': 2009, 'GAIN': 2009, 'STABILIZED': 2009, 'ADEQUATELY': 2009, 'VALUABLE': 2009, 'PERFECT': 2009, 'VERSATILITY': 2009, 'ENHANCING': 2009, 'LOYAL': 2009, 'DISTINCTION': 2009, 'ASSURING': 2009, 'REGAIN': 2009, 'REBOUND': 2009, 'SUCCEEDING': 2009, 'ENABLED': 2009, 'ASSURED': 2009, 'ENTHUSIASTICALLY': 2009, 'REGAINED': 2009, 'DREAM': 2009, 'PERFECTED': 2009, 'ENJOYED': 2009, 'INNOVATIVE': 2009, 'PERFECTS': 2009, 'EMPOWERING': 2009, 'REVOLUTIONIZES': 2009, 'GREATNESS': 2009, 'BOOM': 2009, 'INVENTED': 2009, 'SURPASSED': 2009, 'COMPLIMENT': 2009, 'ENJOYABLY': 2009, 'ENCOURAGING': 2009, 'ACCOMPLISHES': 2009, 'IDEAL': 2009, 'HONORING': 2009, 'OUTPERFORM': 2009, 'SMOOTHLY': 2009, 'DEPENDABILITY': 2009, 'SUCCESS': 2009, 'STRONG': 2009, 'COLLABORATIVE': 2009, 'COLLABORATED': 2009, 'DISTINCTIONS': 2009, 'BOLSTERED': 2009, 'INNOVATE': 2009, 'DISTINCTIVE': 2009, 'ATTAIN': 2009, 'FAVORED': 2009, 'TRANSPARENCY': 2009, 'DELIGHTS': 2009, 'ACCOMPLISHED': 2009, 'SOLVING': 2009, 'SUCCEED': 2009, 'PROGRESSES': 2009, 'ATTAINING': 2009, 'PREMIERE': 2009}\n"
     ]
    }
   ],
   "source": [
    "from xlrd import open_workbook\n",
    "FORMAT = ['Positive', 'Negative']\n",
    "values = \"\"\n",
    "\n",
    "wb = open_workbook('McDonaldDict.xlsx')\n",
    "\n",
    "values = []\n",
    "for s in wb.sheets():\n",
    "    #print 'Sheet:',s.name\n",
    "    words = []\n",
    "    pos = {}\n",
    "    neg = {}\n",
    "    for row in range(1, s.nrows):\n",
    "        col_names = s.row(0)[1:]\n",
    "        col_value = []\n",
    "        word = s.cell(row, 0).value\n",
    "        for name, col in zip(col_names, range(1,s.ncols)):\n",
    "            value  = (s.cell(row,col).value)\n",
    "            if name.value == 'Positive' and int(value) > 0:\n",
    "                pos[word] = int(value)\n",
    "            elif name.value == 'Negative' and int(value) > 0:\n",
    "                neg[word] = int(value)\n",
    "            col_value.append((name.value, value))\n",
    "        values.append(col_value)\n",
    "mcd = McDonald_Word_List(pos, neg)\n",
    "print(mcd.pos_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila. We have our lists of positive and negative words generated. These words were annotated for the financial domain and will be what we use to analyze our pointwise mutual information across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "path = os.getcwd()\n",
    "\n",
    "def extract_header(text):\n",
    "    print(text.replace('\\n',''))\n",
    "    search = re.search('--(.+?)--(.+?)--(.+?)--(.+?)Reuters\\)\\s-', text, flags=re.DOTALL)\n",
    "    text = re.sub('--.+?--.+?--.+?--.+?Reuters\\)\\s-', '', text)\n",
    "    title = search.group(1)\n",
    "    author = search.group(2)\n",
    "    date = search.group(3)\n",
    "    link = search.group(4)\n",
    "    return title, author, date, link, text\n",
    "    \n",
    "\n",
    "reuters_folders = os.listdir('/home/jmkovachi/Documents/jupyter_notebooks/reuters')[0:10]\n",
    "\n",
    "path += '/reuters'\n",
    "\n",
    "articles = []\n",
    "for folder in reuters_folders:\n",
    "    article_files = os.listdir(path + '/' + folder)\n",
    "    for file in article_files:\n",
    "        with open(path + '/' + folder + '/' + file) as f:\n",
    "            raw_text = f.read()\n",
    "            title, author, date, link, text = extract_header(raw_text)\n",
    "            articles.append({title : title, author : author, date : date, link : link, text : text})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this code above to open up our Reuters folder and read the files from our directory. The data being used here comes from this repository [financial news corpus](https://github.com/philipperemy/financial-news-dataset). It is pretty great. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "data = [\n",
    "  ('pfreq', '1'),\n",
    "  ('apikey', 'aikiz3Bel9'),\n",
    "  ('nex', '1'),\n",
    "  ('url', 'https://raw.githubusercontent.com/philipperemy/financial-news-dataset/master/ReutersNews106521/20061020/businesspro-google-dc-idUSN2036351320061020'),\n",
    "]\n",
    "\n",
    "response = requests.post('http://cyn.io/api/', data=data)\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON Mark\n",
      "PERSON John\n",
      "ORGANIZATION Google\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "\n",
    "sentence = \"Mark and John are working at Google.\"\n",
    "\n",
    "for sent in nltk.sent_tokenize(sentence):\n",
    "   for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "      if hasattr(chunk, 'label'):\n",
    "         print(chunk.label(), ' '.join(c[0] for c in chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is some example code from nltk's NE chunker/tagger. It works quite well in our purposes for this PMI task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is where I get into the meat of calculating the PMI. \n",
    "\n",
    "$$pmi(x,y) = log\\frac{p(x,y)}{p(x)p(y)}$$\n",
    "\n",
    "Usually we define p(x,y) as the probability of the intersection of two entities within some window. For the purposes of this experiment, I am defining windows as sentences. Therefore, the equation we arrive for calculating PMI at is:\n",
    "\n",
    "$$pmi(x,y) = log\\frac{count(x,y)_{D}}{count(x)_{D}count(y)_{D}}$$\n",
    "\n",
    "Where $$D$$ is all of the documents in the Reuters corpus. $$x$$ and $$y$$ are occurrences of a polarity word (positive when calculating positive PMI, negative words when calculating negative PMI). \n",
    "\n",
    "Each article is looped through in order to build the overall counts of words in order to count PMIs.\n",
    "\n",
    "Additionally, we store the counts of all words as they relate to organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SOLVING': 2009, 'GOOD': 2009, 'OPTIMISTIC': 2009, 'COLLABORATIVE': 2009, 'ADVANTAGES': 2009, 'EFFICIENCY': 2009, 'DREAM': 2009, 'SATISFACTORILY': 2009, 'SURPASSES': 2009, 'MERITORIOUS': 2009, 'INNOVATING': 2009, 'REVOLUTIONIZED': 2009, 'ASSURING': 2009, 'STABILIZED': 2009, 'REVOLUTIONIZING': 2009, 'COMPLIMENTS': 2009, 'INCREDIBLE': 2009, 'GAINING': 2009, 'PROSPEROUS': 2009, 'DESIRABLE': 2009, 'BENEFITTED': 2009, 'SUCCEEDED': 2009, 'POSITIVELY': 2009, 'IMPRESSIVE': 2009, 'COLLABORATES': 2009, 'DISTINCTIONS': 2009, 'SMOOTH': 2009, 'TRANSPARENCY': 2009, 'ADVANTAGEOUSLY': 2009, 'INNOVATOR': 2009, 'REWARDED': 2009, 'UPTURNS': 2009, 'REVOLUTIONIZES': 2009, 'PROFICIENTLY': 2009, 'ADVANTAGE': 2009, 'ENJOYED': 2009, 'DELIGHTFUL': 2009, 'DELIGHTS': 2009, 'ADVANTAGED': 2009, 'SUPERIOR': 2009, 'SOLVES': 2009, 'ENHANCING': 2009, 'COMPLIMENT': 2009, 'INSIGHTFUL': 2009, 'PROFICIENT': 2009, 'ADVANCEMENT': 2009, 'CONCLUSIVE': 2009, 'PROSPERED': 2009, 'ENJOYABLE': 2009, 'POPULARITY': 2009, 'IMPROVEMENT': 2009, 'HONORABLE': 2009, 'EXCLUSIVES': 2009, 'REBOUND': 2009, 'STRENGTHENED': 2009, 'STRENGTHENS': 2009, 'DISTINCTION': 2009, 'BOLSTERING': 2009, 'DELIGHTED': 2009, 'ENCOURAGING': 2009, 'BENEFIT': 2009, 'EASY': 2009, 'CONSTRUCTIVELY': 2009, 'CREATIVE': 2009, 'PLEASURE': 2009, 'FAVORITES': 2009, 'IMPRESSED': 2009, 'BENEFITING': 2009, 'ADVANTAGEOUS': 2009, 'EXCITEMENT': 2009, 'CONDUCIVE': 2009, 'INVENTION': 2009, 'SURPASSING': 2009, 'BENEFITTING': 2009, 'INVENTED': 2009, 'ENCOURAGEMENT': 2009, 'INVENTORS': 2009, 'DEPENDABILITY': 2009, 'SURPASSED': 2009, 'ACCLAIMED': 2009, 'ENCOURAGES': 2009, 'ADEQUATELY': 2009, 'ATTAIN': 2009, 'REWARD': 2009, 'ASSURES': 2009, 'ENABLE': 2009, 'PERFECTED': 2009, 'FAVORABLE': 2009, 'ENABLED': 2009, 'INVENT': 2009, 'INNOVATES': 2009, 'SATISFACTORY': 2009, 'EASILY': 2009, 'INNOVATIVENESS': 2011, 'ENCOURAGED': 2009, 'DELIGHTING': 2009, 'ABUNDANT': 2009, 'INVENTIVE': 2009, 'STRONGEST': 2009, 'REGAINING': 2009, 'COLLABORATED': 2009, 'COLLABORATIONS': 2009, 'GAINS': 2009, 'ENTHUSIASM': 2009, 'SUCCESSES': 2009, 'OPPORTUNITY': 2009, 'ENABLING': 2009, 'PREEMINENT': 2009, 'SUCCEEDS': 2009, 'COLLABORATOR': 2009, 'PLENTIFUL': 2009, 'SUCCEED': 2009, 'ACHIEVING': 2009, 'IMPROVED': 2009, 'ACCOMPLISH': 2009, 'IMPRESS': 2009, 'DELIGHT': 2009, 'PROSPERING': 2009, 'PERFECTLY': 2009, 'STRENGTH': 2009, 'ATTAINED': 2009, 'STABLE': 2009, 'CHARITABLE': 2009, 'INNOVATE': 2009, 'ENHANCEMENTS': 2009, 'BOLSTERED': 2009, 'BRILLIANT': 2009, 'COMPLIMENTARY': 2009, 'STRONGER': 2009, 'INNOVATORS': 2009, 'ACHIEVEMENTS': 2009, 'BENEFICIAL': 2009, 'BOLSTERS': 2009, 'REGAINED': 2009, 'WIN': 2009, 'UNMATCHED': 2009, 'BETTER': 2009, 'SMOOTHS': 2009, 'SATISFIES': 2009, 'BENEFICIALLY': 2009, 'HIGHEST': 2009, 'REBOUNDING': 2009, 'COLLABORATING': 2009, 'STABILIZATION': 2009, 'ENHANCED': 2009, 'DISTINCTIVENESS': 2009, 'ACCOMPLISHES': 2009, 'PLEASED': 2009, 'PROACTIVELY': 2009, 'SATISFY': 2009, 'RECEPTIVE': 2009, 'COMPLIMENTED': 2009, 'PRESTIGIOUS': 2009, 'ENABLES': 2009, 'EASIER': 2009, 'VALUABLE': 2009, 'GREATLY': 2009, 'POSITIVE': 2009, 'INFLUENTIAL': 2009, 'SMOOTHING': 2009, 'ACCOMPLISHMENT': 2009, 'LEADERSHIP': 2009, 'SATISFYING': 2009, 'IMPRESSING': 2009, 'UNPARALLELED': 2009, 'SPECTACULARLY': 2009, 'EXCEPTIONALLY': 2009, 'VIBRANT': 2009, 'INGENUITY': 2009, 'SUCCEEDING': 2009, 'BEAUTIFULLY': 2009, 'INNOVATION': 2009, 'INFORMATIVE': 2009, 'EMPOWERS': 2009, 'IMPRESSIVELY': 2009, 'SUCCESSFUL': 2009, 'PROSPERITY': 2009, 'INVENTOR': 2009, 'ALLIANCE': 2009, 'SATISFACTION': 2009, 'EFFICIENT': 2009, 'EMPOWERED': 2009, 'STRENGTHENING': 2009, 'EMPOWERING': 2009, 'COLLABORATORS': 2009, 'EXCEPTIONAL': 2009, 'SUCCESS': 2009, 'STRONG': 2009, 'REWARDING': 2009, 'FANTASTIC': 2009, 'EXCITED': 2009, 'EFFICIENCIES': 2009, 'PERFECTS': 2009, 'PROGRESS': 2009, 'SUCCESSFULLY': 2009, 'PROGRESSING': 2009, 'ACHIEVEMENT': 2009, 'LUCRATIVE': 2009, 'EXEMPLARY': 2009, 'DESIRED': 2009, 'CREATIVENESS': 2009, 'REGAIN': 2009, 'ACHIEVES': 2009, 'PREEMINENCE': 2009, 'STABILITY': 2009, 'ENHANCEMENT': 2009, 'EXCELS': 2009, 'COURTEOUS': 2009, 'COLLABORATION': 2009, 'EMPOWER': 2009, 'ATTRACTIVE': 2009, 'HONOR': 2009, 'DILIGENTLY': 2009, 'PERFECT': 2009, 'GREATER': 2009, 'DESPITE': 2009, 'CONFIDENT': 2009, 'SATISFIED': 2009, 'VERSATILE': 2009, 'GAINED': 2009, 'EXCELLENCE': 2009, 'WINNERS': 2009, 'EXCITING': 2009, 'INSPIRATIONAL': 2009, 'VERSATILITY': 2009, 'STRENGTHEN': 2009, 'PROFITABLE': 2009, 'ENJOYABLY': 2009, 'STABILIZING': 2009, 'BREAKTHROUGHS': 2009, 'STRENGTHS': 2009, 'UPTURN': 2009, 'ENTHUSIASTIC': 2009, 'ADVANCES': 2009, 'SMOOTHLY': 2009, 'ATTAINMENTS': 2009, 'BENEFITED': 2009, 'CREATIVITY': 2009, 'INNOVATIONS': 2009, 'ENHANCES': 2009, 'WINNER': 2009, 'IDEAL': 2009, 'STABILIZES': 2009, 'INSPIRATION': 2009, 'ACCOMPLISHMENTS': 2009, 'DELIGHTFULLY': 2009, 'OUTPERFORMING': 2009, 'BOOSTED': 2009, 'HAPPY': 2009, 'PROFITABILITY': 2009, 'SPECTACULAR': 2009, 'INVENTIONS': 2009, 'LOYAL': 2009, 'PLEASANTLY': 2009, 'DISTINCTIVELY': 2009, 'ATTAINS': 2009, 'ENJOYS': 2009, 'OUTPERFORMED': 2009, 'HAPPINESS': 2009, 'EXCLUSIVE': 2009, 'ACCOMPLISHED': 2009, 'PREMIER': 2009, 'INCREDIBLY': 2009, 'POPULAR': 2009, 'FAVORITE': 2009, 'PROFITABLY': 2009, 'BOOMING': 2009, 'BOOST': 2009, 'ASSURE': 2009, 'ENJOYING': 2009, 'OUTPERFORM': 2009, 'EXCLUSIVENESS': 2009, 'ATTAINING': 2009, 'GAIN': 2009, 'EFFICIENTLY': 2009, 'IMPROVEMENTS': 2009, 'RESOLVE': 2009, 'TREMENDOUSLY': 2009, 'UNSURPASSED': 2009, 'INVENTING': 2009, 'IMPROVES': 2009, 'FAVORING': 2009, 'IMPROVING': 2009, 'DILIGENT': 2009, 'CONSTRUCTIVE': 2009, 'EXCELLING': 2009, 'CONCLUSIVELY': 2009, 'PROFICIENCY': 2009, 'HONORED': 2009, 'ACHIEVED': 2009, 'EXCELLENT': 2009, 'VIBRANCY': 2009, 'HONORS': 2009, 'INVENTIVENESS': 2009, 'DISTINCTIVE': 2009, 'HAPPILY': 2009, 'FAVORABLY': 2009, 'ASSURED': 2009, 'PLEASANT': 2009, 'INNOVATIVE': 2009, 'GREATNESS': 2009, 'IMPRESSES': 2009, 'ENJOY': 2009, 'EFFECTIVE': 2009, 'HAPPIEST': 2009, 'OPPORTUNITIES': 2009, 'ENJOYMENT': 2009, 'ADVANCING': 2009, 'EXCLUSIVELY': 2009, 'ACHIEVE': 2009, 'HONORING': 2009, 'ABUNDANCE': 2009, 'PRESTIGE': 2009, 'BOOM': 2009, 'PROSPERS': 2009, 'PROGRESSED': 2009, 'ATTRACTIVENESS': 2009, 'ENTHUSIASTICALLY': 2009, 'WINNING': 2009, 'TREMENDOUS': 2009, 'BREAKTHROUGH': 2009, 'INNOVATED': 2009, 'FRIENDLY': 2009, 'ENHANCE': 2009, 'OUTPERFORMS': 2009, 'CREATIVELY': 2009, 'COLLABORATE': 2009, 'SURPASS': 2009, 'COMPLIMENTING': 2009, 'ABLE': 2009, 'LEADING': 2009, 'INTEGRITY': 2009, 'PROACTIVE': 2009, 'BEST': 2012, 'WORTHY': 2009, 'GREAT': 2009, 'REWARDS': 2009, 'REVOLUTIONIZE': 2009, 'ADVANCEMENTS': 2009, 'IMPROVE': 2009, 'PROGRESSES': 2009, 'EXCLUSIVITY': 2009, 'DESTINED': 2009, 'PREMIERE': 2009, 'STABILIZE': 2009, 'DEPENDABLE': 2009, 'STABILIZATIONS': 2009, 'GREATEST': 2009, 'REBOUNDED': 2009, 'FAVORED': 2009, 'ATTAINMENT': 2009, 'BEAUTIFUL': 2009, 'ALLIANCES': 2009, 'ACCOMPLISHING': 2009}\n"
     ]
    }
   ],
   "source": [
    "print(mcd.pos_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def num_words(sentences):\n",
    "    l = 0\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    for s in sentences:\n",
    "        l += len(s)\n",
    "        for word in nltk.word_tokenize(s):\n",
    "            if word.upper() in mcd.pos_words:\n",
    "                pos_count += 1\n",
    "            elif word.upper() in mcd.neg_words:\n",
    "                neg_count += 1\n",
    "    return l, pos_count, neg_count\n",
    "\n",
    "def compute_PMI(class1, class2, int_c1c2, overall_count):\n",
    "    return math.log((int_c1c2+1/overall_count)/((class1+1/overall_count)*(class2+1/overall_count)))\n",
    "    # +1s added for smoothing\n",
    "\n",
    "l = 0\n",
    "overall_pos = 0\n",
    "overall_neg = 0\n",
    "overall_org = 0\n",
    "intersection_pos = 0\n",
    "intersection_neg = 0\n",
    "\n",
    "pos_df = pd.DataFrame(0, index=[str(key) for (key,val) in mcd.pos_words.items()], columns=[])\n",
    "neg_df = pd.DataFrame(0, index=[str(key) for (key,val) in mcd.neg_words.items()], columns=[])\n",
    "for article in articles[:1000]:\n",
    "    sentences = nltk.sent_tokenize(article.text)\n",
    "    tmpL, tmp_pos, tmp_neg = num_words(sentences)\n",
    "    l += tmpL\n",
    "    overall_pos += tmp_pos\n",
    "    overall_neg += tmp_neg\n",
    "    for sent in sentences:\n",
    "       org_count = 0\n",
    "       pos_count = 0\n",
    "       neg_count = 0\n",
    "       org_list = []\n",
    "       chunks = [chunk for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)))]\n",
    "       for chunk in chunks:\n",
    "            if hasattr(chunk, 'label') and str(chunk.label()) == 'ORGANIZATION':\n",
    "                #print(chunk.label())\n",
    "                org_count += 1\n",
    "                overall_org += 1\n",
    "                org_list.append(str(chunk[0]).upper())\n",
    "                if str(chunk[0]).upper() not in pos_df.columns:\n",
    "                    print(str(chunk[0]).upper())\n",
    "                    pos_df[str(chunk[0]).upper()] = np.zeros(len(pos_df.index))\n",
    "                    neg_df[str(chunk[0]).upper()] = np.zeros(len(neg_df.index))\n",
    "                \n",
    "       tmp_org_count = org_count\n",
    "       for chunk in chunks:\n",
    "            #print(chunk[0])\n",
    "            #print(mcd.pos_words)\n",
    "            if str(chunk[0]).upper() in mcd.pos_words:\n",
    "                tmp_org_list = org_list\n",
    "                #print(chunk[0])\n",
    "                pos_org_count = tmp_org_count\n",
    "                while len(tmp_org_list) > 0:\n",
    "                    pos_count += 1\n",
    "                    pos_df.at[str(chunk[0]).upper(), tmp_org_list[0]] += 1\n",
    "                    tmp_org_list.pop(0)\n",
    "                    mcd.intersection_pos[str(chunk[0]).upper()] += 1\n",
    "                mcd.pos_word_counts[str(chunk[0]).upper()] += 1\n",
    "            elif str(chunk[0]).upper() in mcd.neg_words:\n",
    "                #print(chunk[0])\n",
    "                tmp_org_list = org_list  \n",
    "                while(len(tmp_org_list) > 0):\n",
    "                    neg_count += 1\n",
    "                    neg_df.at[str(chunk[0]).upper(), tmp_org_list[0]] += 1\n",
    "                    tmp_org_list.pop(0)\n",
    "                    mcd.intersection_neg[str(chunk[0]).upper()] += 1\n",
    "                mcd.neg_word_counts[str(chunk[0]).upper()] += 1\n",
    "       intersection_pos += org_count if org_count < pos_count else pos_count\n",
    "       intersection_neg += org_count if org_count < neg_count else neg_count\n",
    "    #print(pos_count)\n",
    "    #print(overall_org)\n",
    "    #print(intersection)\n",
    "    #print(l)\n",
    "    \n",
    "print(compute_PMI(overall_pos, overall_org, intersection_pos, l))\n",
    "print(compute_PMI(overall_neg, overall_org, intersection_neg, l))\n",
    "#print(mcd.pos_word_counts)\n",
    "print(pos_df)\n",
    "\n",
    "\n",
    "            \n",
    "                \n",
    "        \n",
    "              #print(chunk.label(), ' '.join(c[0] for c in chunk))\n",
    "    #create_co_occurrence_matrix(sentences)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\n",
    "Here is the above algorithm:\n",
    "\n",
    "\\begin{enumerate}\n",
    "    \\item Initialize two empty Pandas dataframes, one for the positive words and one for the negative words.\n",
    "    \\item Loop through each article:\n",
    "    \\begin{enumerate}\n",
    "        \\item Tokenize each sentence in the article using NLTK.\n",
    "            \\begin{enumerate}\n",
    "                \\item Initialize an organization word count, a positive word count, a negative word count, and an empty list of orgs.\n",
    "                \\item Chunk the sentence using the NLTK NER chunker. Loop through each chunk and append the organization to the org list. If the organization is not present in the columns of the dataframe, insert a new column into the dataframe. \n",
    "                \\item Loop through the chunks a second time. If the chunked word is in the positive (or negative, conversely) words dict, create a temporary organization list and increment the counts of the positive (negative) count (representing the number of co-occurrences in a sentence) and increment the index in the pandas dataframe corresponding to that positive or negative word.\n",
    "            \\end{enumerate}\n",
    "    \\end{enumerate}\n",
    "\\end{enumerate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sorted_counts = sorted(mcd.pos_word_counts.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(sorted_counts)\n",
    "print(sorted_counts[50][0])\n",
    "print(mcd.intersection_pos[sorted_counts[50][0]])\n",
    "print(compute_PMI(sorted_counts[100][1], overall_org, mcd.intersection_pos[sorted_counts[100][0]], l))\n",
    "\n",
    "sorted_counts[0:50]\n",
    "\n",
    "plt.figure(figsize=(20, 3))  # width:20, height:3\n",
    "# save the names and their respective scores separately\n",
    "# reverse the tuples to go from most frequent to least frequent \n",
    "plt.bar(range(len(sorted_counts[0:20])), [val[1] for val in sorted_counts[0:20]], align='edge', width=.3)\n",
    "plt.xticks(range(len(sorted_counts[0:20])), [val[0] for val in sorted_counts[:20]])\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "PMIs = [compute_PMI(count[1], overall_org, mcd.intersection_pos[count[0]], l) for count in sorted_counts[0:20]]\n",
    "\n",
    "plt.figure(figsize=(20, 3))  # width:20, height:3\n",
    "# save the names and their respective scores separately\n",
    "# reverse the tuples to go from most frequent to least frequent \n",
    "plt.bar(range(len(sorted_counts[0:20])), PMIs, align='edge', width=.3)\n",
    "plt.xticks(range(len(sorted_counts[0:20])), [val[0] for val in sorted_count[:20]])\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
